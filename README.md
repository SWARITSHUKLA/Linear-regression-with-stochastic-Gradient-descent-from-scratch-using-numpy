# Linear-regression-with-stochastic-Gradient-descent-from-scratch-using-numpy
This is a python code that showcases the use of Stochastic gradient descent in simple Linear regression, instead of calculating the gradient of the batch at every step we will use one target at a time

# Why do we use stochastic gradient descent?
 Stochastic gradient descent is very fast and yet effective, but the down side is it carries a lot of noise, This issue can be resolved if you just increase the number of iterations
 To give you an intuition in this code i have done 2 million stochastic gradient step and it only took 1 minute and 11 seconds.
 PS: my laptop is slow :(
